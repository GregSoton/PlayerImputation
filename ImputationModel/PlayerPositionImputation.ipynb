{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb2fa1a3-b3b0-478c-81f9-0da21d1efb66",
   "metadata": {},
   "source": [
    "# Player Position Imputation\n",
    "Needed installs: Torch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e901cec-2aca-4bdd-80ef-af0a81437828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Apps\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "C:\\Apps\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.Float64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "C:\\Apps\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:369: FutureWarning: pandas.UInt64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  _numeric_index_types = (pd.Int64Index, pd.Float64Index, pd.UInt64Index)\n",
      "C:\\Apps\\Anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "import ImputationModel.feature_engineering as fe\n",
    "import UtilFunctions.util_functions as util_functions\n",
    "import ImputationModel.model_functions as mf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn import preprocessing\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "import ImputationModel.Models.Time_LSTM_Module as TLSTM_module\n",
    "import ImputationModel.Models.Time_LSTM as TLSTM\n",
    "import ImputationModel.Models.GNN as GNN\n",
    "import ImputationModel.Models.Agent_Imputer as AgentImputer\n",
    "import ImputationModel.Models.Baselines as BL\n",
    "\n",
    "fps = 30."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabe7f6-a244-495b-8dfb-f03414ec0fa0",
   "metadata": {},
   "source": [
    "# Section 1: Loading in the data\n",
    "Step 1: Load in the available games\n",
    "\n",
    "Step 2: Get event & tracking dataframes for all games\n",
    "\n",
    "Step 3: Construct dataframe using the feature set described in the paper\n",
    "\n",
    "Step 4: Sort the DataFrame by event so we get all players for each event in blocks\n",
    "\n",
    "Step 5: Normalize the data\n",
    "\n",
    "Step 6: Get data sequences to pass into the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c8ea3-7d18-4621-a51e-879dbebe5bca",
   "metadata": {},
   "source": [
    "### Step 1: Load in the available games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e84a674f-792c-4466-8e07-cf5130e123b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>home_id</th>\n",
       "      <th>away_id</th>\n",
       "      <th>home_score</th>\n",
       "      <th>away_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26223</td>\n",
       "      <td>2021-02-27 16:30:00+09:00</td>\n",
       "      <td>4644</td>\n",
       "      <td>4220</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26238</td>\n",
       "      <td>2021-03-07 16:30:00+09:00</td>\n",
       "      <td>316</td>\n",
       "      <td>4220</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26334</td>\n",
       "      <td>2021-03-10 19:30:00+09:00</td>\n",
       "      <td>4220</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                       date  home_id  away_id  home_score  away_score\n",
       "0  26223  2021-02-27 16:30:00+09:00     4644     4220           1           1\n",
       "1  26238  2021-03-07 16:30:00+09:00      316     4220           3           0\n",
       "2  26334  2021-03-10 19:30:00+09:00     4220      328           0           0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suwon_match_df = pd.read_csv('data/Suwon_FC/Suwon_games.csv')\n",
    "suwon_match_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92d2bb8-1893-4c16-b599-cbcee341066c",
   "metadata": {},
   "source": [
    "### Step 2: Get Event and Tracking dataframes for all games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aeed9c4-3743-4b6a-b528-df6299df0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dfs = []\n",
    "tracking_dfs = []\n",
    "home_dfs = []\n",
    "away_dfs = []\n",
    "formation_dfs = []\n",
    "num_games = 34\n",
    "count=0\n",
    "\n",
    "for i in range(1,num_games+1):\n",
    "    events_df, tracking_df, home_df, away_df, formation_df = util_functions.get_suwon_dataframes('game'+str(i))\n",
    "    events_df['id'] = range(count,count+len(events_df))\n",
    "    count+=len(events_df)\n",
    "    events_dfs.append(events_df)\n",
    "    tracking_dfs.append(tracking_df)\n",
    "    home_dfs.append(home_df)\n",
    "    away_dfs.append(away_df)\n",
    "    formation_dfs.append(formation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791307bc-20a7-4b11-a9e7-e372de0a4e85",
   "metadata": {},
   "source": [
    "### Step 3: Construct dataframe using the feature set described in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2298c-121a-4121-a45f-1761f475e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_num_input = pd.DataFrame()\n",
    "whole_cat_input = pd.DataFrame()\n",
    "whole_input = pd.DataFrame()\n",
    "whole_label = np.empty((0,2), float)\n",
    "for i in range(0,num_games):\n",
    "    num_input, cat_input, label,tdf,edf,input_data = fe.get_game_data(events_dfs[i],tracking_dfs[i],home_dfs[i],away_dfs[i],util_functions.get_goalkeepers(home_dfs[i],away_dfs[i]), formation_dfs[i])\n",
    "    whole_input = whole_input.append(input_data)\n",
    "    whole_label = np.append(whole_label,label,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd902349-d9a4-49dd-98a3-c83a0bb3c898",
   "metadata": {},
   "source": [
    "### Step 4: Sort the DataFrame by event so we get all players for each event in blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b09b7-f89d-495b-8e5b-508f788f0e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_whole_input_df, sorted_labels = fe.custom_sort(whole_input, whole_label)\n",
    "sorted_whole_input_df = sorted_whole_input_df.reset_index(drop=True)\n",
    "sorted_labels = torch.tensor(sorted_labels)\n",
    "sorted_whole_input_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2d7af3-ad3a-4ce2-8405-767ed90f901a",
   "metadata": {},
   "source": [
    "### Optional Step - Load in pre-saved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b93e22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted_whole_input_df = pd.read_csv('sorted_whole_input_df_time.csv')[:66000]\n",
    "#sorted_labels = torch.tensor(np.array(pd.read_csv('swid_labels.csv')))[:66000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95db2a99-6db4-4809-9345-e3c8a7d68f97",
   "metadata": {},
   "source": [
    "### Step 5: Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa8db488-777d-4fd3-891b-2297797a8c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folds (e.g. data to put into the test set) based on match ids\n",
    "fold1=sorted_whole_input_df[sorted_whole_input_df['match_id'].isin([26223])].index\n",
    "fold2=sorted_whole_input_df[sorted_whole_input_df['match_id'].isin([26441, 26386, 42921])].index\n",
    "\n",
    "\"\"\"Folds used in paper: fold1=sorted_whole_input_df[sorted_whole_input_df['match_id'].isin([42926, 42937, 42945])].index\n",
    "fold2=sorted_whole_input_df[sorted_whole_input_df['match_id'].isin([26441, 26386, 42921])].index\n",
    "fold3=sorted_whole_input_df[sorted_whole_input_df['match_id'].isin([26423, 26428, 26433])].index\n",
    "fold4=sorted_whole_input_df[sorted_whole_input_df['match_id'].isin([26223, 26238, 26334])].index\n",
    "fold5=sorted_whole_input_df[sorted_whole_input_df['match_id'].isin([26248, 26255, 26257])].index\"\"\"\n",
    "\n",
    "time_scaler = RobustScaler()\n",
    "timestamps = torch.tensor(time_scaler.fit_transform(np.array(sorted_whole_input_df['time_since_last_pred']).reshape(-1,1))).reshape(-1)\n",
    "sorted_wi_num = sorted_whole_input_df[['ballx','prev_player_x','next_player_x','bally','prev_player_y','next_player_y','av_player_x','av_player_y','time_since_last_pred','prev_player_time','next_player_time']]\n",
    "sorted_wi_cat = sorted_whole_input_df[['position','event_type','team_on_ball','player_on_ball','goal_diff']]\n",
    "input_data_normalized, label_data_normalized, scaler = fe.preprocess_data(sorted_wi_num, sorted_wi_cat, sorted_labels, fold1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e82e18-a7ef-4238-a90e-d446273555a8",
   "metadata": {},
   "source": [
    "### Step 6: Create seqeuences from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bde1d626-cdcd-4c2a-847d-4bfe73ca1ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ss, y_mm, ts, out_inds = fe.split_sequences(sorted_whole_input_df, input_data_normalized, label_data_normalized, timestamps, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432054c8-d099-463d-8c33-869a996ef00c",
   "metadata": {},
   "source": [
    "# Section 2: Create Training/Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dc0f464-6642-4f65-85a0-540fdfeaa3df",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[899, 22, 5, 60]' is invalid for input of size 5043390",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f6d6b7b0c1f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Put into format of 22 event sequences for an event (representing each player) and put into data loaders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseries_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_ts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseries_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_ts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - University of Southampton\\Documents\\GitHub\\PlayerImputation\\ImputationModel\\feature_engineering.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, t, feature_num)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mseries_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m22\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[899, 22, 5, 60]' is invalid for input of size 5043390"
     ]
    }
   ],
   "source": [
    "#Split data into train and test data\n",
    "X_train, X_test, y_train, y_test, X_train_ts, X_test_ts = fe.get_train_test_split(sorted_whole_input_df, X_ss, y_mm, ts, fold1)\n",
    "\n",
    "#Put into format of 22 event sequences for an event (representing each player) and put into data loaders\n",
    "train_data = fe.series_data(X_train, y_train, X_train_ts, 66)\n",
    "test_data = fe.series_data(X_test, y_test, X_test_ts, 66)\n",
    "train_loader = DataLoader(train_data,shuffle=False,batch_size=512)\n",
    "test_loader = DataLoader(test_data,shuffle=False,batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08cc771-bcb2-42ab-a95b-1915d96abb63",
   "metadata": {},
   "source": [
    "Create edge index for fully connected graph network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3508e981-264f-4b25-82fc-baa1d683787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connects players to every other player in the graph neural network\n",
    "t1 = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]\n",
    "list_edges = list(itertools.product(t1, t1))\n",
    "for l in list_edges:\n",
    "    if l[0] == l[1]:\n",
    "        list_edges.remove(l)\n",
    "list_edges = [list(ele) for ele in list_edges]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3396a30f-173f-488b-a036-c0392b568dab",
   "metadata": {},
   "source": [
    "# Section 3: Load and Run Models\n",
    "Model Types:\n",
    "\n",
    "1. Agent Imputer - AgentImputer.AgentImputer\n",
    "2. Time-LSTM = TLSTM.Time_LSTM\n",
    "3. GNN = GNN.GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5897b57e-da3f-409d-9525-459a53cb637f",
   "metadata": {},
   "source": [
    "### Step 1: Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543af82-77ea-4b35-8010-72e2ffc74f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AgentImputer.AgentImputer(input_size = X_train[0].shape[1])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8243ee-7adb-4343-a0fc-c3b37c3aae3e",
   "metadata": {},
   "source": [
    "### Step 2: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cbd442-030d-4ba5-9179-a5ac25a9ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_preds = mf.model_training(train_loader, X_train_ts, model, optimizer, list_edges, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f5bf8-c597-46e6-a2b1-9635d6fafa8c",
   "metadata": {},
   "source": [
    "### Step 3: Make Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5988d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_predictions, actual_test_results = mf.get_test_predictions(test_loader, model, y_test, list_edges, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a52d2-398f-43c6-8784-03185a1aba62",
   "metadata": {},
   "source": [
    "# Section 4: Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcec7d14-c07c-4745-b8b5-d09bab3121c4",
   "metadata": {},
   "source": [
    "Function which calculates and shows the error in predictions for train or test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a8163b-0402-4da7-94be-a5c2549da98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_analytics(actual_predictions, actual_test_results, num_preds):\n",
    "    actual_predictions = actual_predictions.reshape(num_preds,2)\n",
    "    actual_test_results = actual_test_results.reshape(num_preds,2)\n",
    "    plt.plot(actual_predictions)\n",
    "    plt.plot(actual_test_results)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Dist: \", np.mean([np.linalg.norm(actual_predictions[i]-np.array(actual_test_results[i])) for i in range(len(actual_predictions))]))\n",
    "    print(\"X Dist: \", np.mean(abs(actual_predictions[:,0] - np.array(actual_test_results[:,0]))))\n",
    "    print(\"Y Dist: \", np.mean(abs(actual_predictions[:,1] - np.array(actual_test_results[:,1]))))\n",
    "    return np.mean([np.linalg.norm(actual_predictions[i]-np.array(actual_test_results[i])) for i in range(len(actual_predictions))]),np.mean(abs(actual_predictions[:,0] - np.array(actual_test_results[:,0]))),np.mean(abs(actual_predictions[:,1] - np.array(actual_test_results[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19c60eb-fd63-4b7c-84bc-7397e2c1fd39",
   "metadata": {},
   "source": [
    "### Step 1: Show accuracy for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34ad0a7-5220-4b29-a122-46bce65be9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test data Results: \")\n",
    "prediction_analytics(actual_predictions, actual_test_results, y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd146d73-1bfb-42aa-9ea2-f071c38bad4a",
   "metadata": {},
   "source": [
    "### Step 2: Show accuracy for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff936f-94b1-4a9a-8314-36393f8b6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = [t.tolist() for t in y_preds]\n",
    "actual_train_preds = scaler.inverse_transform(np.array([item for sublist in train_preds for item in sublist]).reshape(y_train.shape[0],2))\n",
    "print(\"Train data Results: \")\n",
    "prediction_analytics(actual_train_preds,scaler.inverse_transform(y_train),y_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bb2b35-0cf1-44cd-a929-0d93d5e624fe",
   "metadata": {},
   "source": [
    "# Section 5: Generate and run Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a29448-0129-43f0-9eb0-f592ec329100",
   "metadata": {},
   "source": [
    "### Get data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69f31e4-cf93-4801-ba80-ee6ff2eeefd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_x_train,base_x_train_cat,base_x_test,base_x_test_cat,base_y_train,base_y_test,xg_cat_train,xg_cat_test = BL.get_baseline_data(sorted_whole_input_df, sorted_labels, fold1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cd1f68-6a24-4eb3-9d55-a16f78aec4bd",
   "metadata": {},
   "source": [
    "### Baseline 1 - Average Seen Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f334fab-d97a-4ac5-8985-885f1224ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline 1 distance error: \", BL.baseline_1(base_x_test.copy(), base_y_test)[0])\n",
    "print(\"Baseline 1 distance error Train: \", BL.baseline_1(base_x_train.copy(), base_y_train)[0])\n",
    "\n",
    "#Load results for baseline 1 and stores prediction in dataframe\n",
    "#Duplicate code for other baseline models if you are looking to save baseline results for other models\n",
    "_,b1_results = BL.baseline_1(base_x_test.copy(),base_y_test)\n",
    "b1_results[['act_x','act_y']] = base_y_test\n",
    "b1_results = b1_results.reset_index(drop=True)\n",
    "b1_results['dist'] = [np.linalg.norm(np.array(b1_results.loc[i][['pred_x','pred_y']])-base_y_test[i]) for i in range(len(base_y_test))]\n",
    "b1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa780d4-6b1f-4e5d-a733-c0129e188eea",
   "metadata": {},
   "source": [
    "### Baseline 2 - Time-Scaled Average Seen Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb971abf-b601-4a79-9d08-c1af4d490f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline 2 distance error: \", BL.baseline_2(base_x_test.copy(), base_y_test)[1])\n",
    "print(\"Baseline 2 distance error train: \", BL.baseline_2(base_x_train.copy(), base_y_train)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663ea025-004c-48d3-9b93-2adb12f5c4b5",
   "metadata": {},
   "source": [
    "### Baseline 3 - Average Player Location Over a Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d0291-fe34-44bc-92ae-576bee268014",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3_preds = np.array(base_x_test[['av_player_x','av_player_y']])\n",
    "print(\"X error: \", np.mean(abs(b3_preds[:,0].reshape(len(b3_preds),1)-base_y_test[:,0].reshape(len(b3_preds),1))))\n",
    "print(\"Y error: \", np.mean(abs(b3_preds[:,1].reshape(len(b3_preds),1)-base_y_test[:,1].reshape(len(b3_preds),1))))\n",
    "print(\"Distance error: \", np.mean([np.linalg.norm(b3_preds[i]-base_y_test[i]) for i in range(len(b3_preds))]))\n",
    "\n",
    "b3_preds_train = np.array(base_x_train[['av_player_x','av_player_y']])\n",
    "print(\"X error train: \", np.mean(abs(b3_preds_train[:,0].reshape(len(b3_preds_train),1)-base_y_train[:,0].reshape(len(b3_preds_train),1))))\n",
    "print(\"Y error train: \", np.mean(abs(b3_preds_train[:,1].reshape(len(b3_preds_train),1)-base_y_train[:,1].reshape(len(b3_preds_train),1))))\n",
    "print(\"Distance error train: \", np.mean([np.linalg.norm(b3_preds_train[i]-base_y_train[i]) for i in range(len(b3_preds_train))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d18d06-9f0a-4f96-9946-e9191592f0ad",
   "metadata": {},
   "source": [
    "### Baseline 4 - XGBoost Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65283619-e433-4063-bf1c-9a4303e5470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_results, xg_preds = BL.xg_boost_baseline(base_x_train, xg_cat_train, base_x_test, xg_cat_test, base_y_train, base_y_test)\n",
    "print(\"XGBoost Regressor Distance Error: \", xg_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67dc639-bc1c-404f-9e13-fe682e72de47",
   "metadata": {},
   "source": [
    "##### View the XGboost predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2221c01e-04ec-4359-b601-3725a633196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_df = base_x_test\n",
    "xgboost_df[['pred_x','pred_y']] = xg_preds\n",
    "xgboost_df[['act_x','act_y']] = base_y_test\n",
    "xgboost_df['dist'] = [math.dist(xgboost_df.iloc[i][['pred_x','pred_y']],xgboost_df.iloc[i][['act_x','act_y']]) for i in range(len(xgboost_df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed07bbca-d2b1-436d-bc8f-edf4906f5745",
   "metadata": {},
   "source": [
    "# Storing the results\n",
    "To view the results of these models and use them to perform downstream tasks you must: Store the results of these in a csv dataframe, including the predicted and actual locations of players along with the original dataset. This then must be stored in a file available for access by the Experiments notebook.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ae38f-ddf4-4832-86db-e5588ec39ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_df.head(2)\n",
    "#xgboost_df.to_csv('ModelResults/xgboost_preds_time.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
