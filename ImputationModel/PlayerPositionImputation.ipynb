{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb2fa1a3-b3b0-478c-81f9-0da21d1efb66",
   "metadata": {},
   "source": [
    "# Player Position Imputation Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e901cec-2aca-4bdd-80ef-af0a81437828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "import ImputationModel.SuwonLSTMFunctions as SLF\n",
    "import UtilFunctions.util_functions as util_functions\n",
    "import UtilFunctions.plot_functions as plot_functions\n",
    "import UtilFunctions.pitch_control as mpc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fps = 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad58eca-b7b6-40e6-b823-613f8cc9dde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feabe7f6-a244-495b-8dfb-f03414ec0fa0",
   "metadata": {},
   "source": [
    "### See the Suwon matches with available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a674f-792c-4466-8e07-cf5130e123b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "suwon_match_df = pd.read_csv('data/Suwon_FC/Suwon_games.csv')\n",
    "suwon_match_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740f28bf-1d6b-4d77-9957-828617e85f1b",
   "metadata": {},
   "source": [
    "### Load in the event and tracking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeed9c4-3743-4b6a-b528-df6299df0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dfs = []\n",
    "tracking_dfs = []\n",
    "home_dfs = []\n",
    "away_dfs = []\n",
    "formation_dfs = []\n",
    "num_games = 34\n",
    "for i in range(1,num_games+1,1):\n",
    "    events_df, tracking_df, home_df, away_df, formation_df = util_functions.get_suwon_dataframes('game'+str(i))\n",
    "    events_dfs.append(events_df)\n",
    "    tracking_dfs.append(tracking_df)\n",
    "    home_dfs.append(home_df)\n",
    "    away_dfs.append(away_df)\n",
    "    formation_dfs.append(formation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534affb6-5f0b-43f1-9626-f841d0e2fcf3",
   "metadata": {},
   "source": [
    "### Get Data for 1 game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29667ff2-dc34-444e-b6ab-217d34229056",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_game1 = events_dfs[4]\n",
    "tracking_game1  = tracking_dfs[4]\n",
    "home_game1 = home_dfs[4]\n",
    "away_game1 = away_dfs[4]\n",
    "home_team,away_team = util_functions.get_teams(events_game1, home_game1)\n",
    "goalkeepers = util_functions.get_goalkeepers(home_game1, away_game1)\n",
    "params = mpc.default_model_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2c942a-bdde-4077-8be6-0ec117c1c99a",
   "metadata": {},
   "source": [
    "### Pytorch Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a6d30-503a-457c-94c4-b8e84badb4de",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import MinMaxScalerDealing with timestep series which has irregular timesteps compared to tasks which use regular timesteps\n",
    "1. LSTM should consider varying time steps/ball movement http://biometrics.cse.msu.edu/Publications/MachineLearning/Baytasetal_PatientSubtypingViaTimeAwareLSTMNetworks.pdf\n",
    "2. Model should include dependency on other player positions (GNN)?\n",
    "3. Adjust hidden cell state function to include time dependency?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b665b92-365a-4e43-981d-74ad74a23aae",
   "metadata": {},
   "source": [
    "### Build an LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515f28e-442b-49a1-910f-d1af3278dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e41c92-3e34-40f2-ae90-fb0e6980cd8c",
   "metadata": {},
   "source": [
    "#### Get input data to model from events and tracking df\n",
    "Takes the event location as input and predicts x location of a player from their tracking at that time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad3a87d-6053-4148-8ed1-eb0d5a175e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tracking_indexes = events_game1.apply(lambda row: util_functions.get_tracking_index_from_event_time(tracking_game1, row['event_time'], row['event_period']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9d3ab-720b-498d-9ea5-00344f5d07f9",
   "metadata": {},
   "source": [
    "Current Input Features: ball_x, last_seen_player_x, next_seen_player_x, ball_y, last_seen_player_y, next_seen_player_y, time_since_last_event, player_role, event_type, team_on_ball, player_on_ball"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9ca84c-b698-48ca-9bd6-ad9ddff701c4",
   "metadata": {},
   "source": [
    "def get_goal_diff(events_df, team_id):\n",
    "    gc = ((events_df['event_types_0_eventType'].str.contains(\"Goal Conceded\")) & (events_df['team_id'] == team_id)).cumsum()\n",
    "    gs = ((events_df['event_types_0_eventType'].str.contains(\"Goal Conceded\")) & (events_df['team_id'] != team_id)).cumsum()\n",
    "    return gs-gc#### Doing some data preprocessing\n",
    "Normalize the input and label data to be between 0 and 1 for pitch coordinates\n",
    "Split data into sequences so last x events are taken into account by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35768b4-0819-436e-9e40-dbec6df987cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goal_diff(events_df, team_id):\n",
    "    gc = ((events_df['event_types_0_eventType'].str.contains(\"Goal Conceded\")) & (events_df['team_id'] == team_id)).cumsum()\n",
    "    gs = ((events_df['event_types_0_eventType'].str.contains(\"Goal Conceded\")) & (events_df['team_id'] != team_id)).cumsum()\n",
    "    return gs-gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8cf24-a901-4ab3-9a30-4de66fcf8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_data(events_df, tracking_df, home_df, away_df, goalkeepers, formation):\n",
    "    tracking_indexes = SLF.get_tracking_indexes(events_df, tracking_df)\n",
    "    whole_input = pd.DataFrame()\n",
    "    whole_label = np.empty((0,2), float)\n",
    "    home_team,away_team = util_functions.get_teams(events_df, home_df)\n",
    "    \n",
    "    home_goal_diff = pd.Series(get_goal_diff(events_df,home_team),name='goal_diff')\n",
    "    away_goal_diff = pd.Series(get_goal_diff(events_df,away_team),name='goal_diff')\n",
    "    \n",
    "    for player in home_df['player_id']:\n",
    "        if 'player_'+str(player)+'_x' in tracking_df.columns:\n",
    "            input_data, label_data = SLF.get_data(events_df,tracking_df, int(player), home_df, goalkeepers[0],tracking_indexes, home_goal_diff, formation)\n",
    "            whole_input = whole_input.append(input_data)\n",
    "            whole_label = np.append(whole_label,label_data,axis=0)\n",
    "\n",
    "    for player in away_df['player_id']:\n",
    "        if 'player_'+str(player)+'_x' in tracking_df.columns:\n",
    "            input_data, label_data = SLF.get_data(events_df,tracking_df, int(player), away_df, goalkeepers[1],tracking_indexes, away_goal_diff, formation)\n",
    "            whole_input = whole_input.append(input_data)\n",
    "            whole_label = np.append(whole_label,label_data,axis=0)\n",
    "\n",
    "    whole_cat_input = whole_input[['position','event_type','team_on_ball','player_on_ball','goal_diff']]\n",
    "    whole_num_input = whole_input[whole_input.columns[~whole_input.columns.isin(['position','event_type','team_on_ball','player_on_ball','goal_diff'])]]\n",
    "    return whole_num_input, whole_cat_input, whole_label, tracking_df.loc[tracking_indexes][:],events_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2298c-121a-4121-a45f-1761f475e850",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_num_input = pd.DataFrame()\n",
    "whole_cat_input = pd.DataFrame()\n",
    "whole_label = np.empty((0,2), float)\n",
    "for i in range(0,2):\n",
    "    num_input, cat_input, label,tdf,edf = get_game_data(events_dfs[i],tracking_dfs[i],home_dfs[i],away_dfs[i],util_functions.get_goalkeepers(home_dfs[i],away_dfs[i]), formation_dfs[i])\n",
    "    whole_num_input = whole_num_input.append(num_input)\n",
    "    whole_cat_input = whole_cat_input.append(cat_input)\n",
    "    whole_label = np.append(whole_label,label,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8db488-777d-4fd3-891b-2297797a8c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scaler = RobustScaler()\n",
    "timestamps = torch.tensor(time_scaler.fit_transform(np.array(whole_num_input['time_since_last_pred']).reshape(-1,1))).reshape(-1)\n",
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7df868c-ba87-4404-aa44-400be41da552",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_normalized, label_data_normalized, scaler = SLF.preprocess_data(whole_num_input, whole_cat_input, whole_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc98b53-b1ef-4152-b3a7-c8a3fcb8b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ss, y_mm = SLF.split_sequences(input_data_normalized, label_data_normalized, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5c5d4-77c9-41c9-851c-92b70613bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(input_sequences, output_sequence, timestamps, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list() # instantiate X and y\n",
    "    ts = list()\n",
    "    for i in range(len(input_sequences)):\n",
    "        # find the end of the input, output sequence\n",
    "        end_ix = i + n_steps_in + n_steps_out \n",
    "        out_end_ix = end_ix - n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix == len(input_sequences): break\n",
    "        # gather input and output of the pattern\n",
    "        seq_x, seq_y = input_sequences[i:end_ix+1], output_sequence[out_end_ix]\n",
    "        timestamp = timestamps[i:end_ix+1]\n",
    "        X.append(seq_x), y.append(seq_y), ts.append(timestamp)\n",
    "    return X, y, ts\n",
    "\n",
    "X_ss, y_mm, ts = split_sequences(input_data_normalized, label_data_normalized, timestamps, 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ebc27d-3209-4b48-8adf-94a5259b18f5",
   "metadata": {},
   "source": [
    "#### Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f30102-9cfd-4ad1-94a3-ff210c372ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(X_ss, y_mm, ts):\n",
    "    X_train = X_ss[:-50000]\n",
    "    X_test = X_ss[-50000:]\n",
    "    X_train_ts = ts[:-50000]\n",
    "    X_test_ts = ts[-50000:]\n",
    "\n",
    "    y_train = torch.tensor(y_mm[:-50000])\n",
    "    y_test = torch.tensor(y_mm[-50000:])\n",
    "    return X_train, X_test, y_train, y_test, X_train_ts, X_test_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc0f464-6642-4f65-85a0-540fdfeaa3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_train_ts, X_test_ts = get_train_test_split(X_ss, y_mm, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8206db-c2c2-4af9-a761-c99ab8403d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class series_data(Dataset):\n",
    "    def __init__(self,x,y,t):\n",
    "        self.x = torch.stack(x)\n",
    "        self.y = torch.tensor(y,dtype=torch.float32)\n",
    "        self.t = torch.stack(t)\n",
    "        self.len = len(x)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx],self.t[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "train_data = series_data(X_train, y_train, X_train_ts)\n",
    "test_data = series_data(X_test, y_test, X_test_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f121e2ab-8195-482d-9d7c-1efb21757afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[:][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce910f1-1208-4fab-8d95-d2fa49d31489",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[:][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894458e8-6b6a-44dd-bdb3-82a541f602f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "train_loader = DataLoader(train_data,shuffle=False,batch_size=512)\n",
    "test_loader = DataLoader(test_data,shuffle=False,batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f54db6-8f68-4365-a58f-ebcc3d4b648c",
   "metadata": {},
   "source": [
    "#### Create LSTM model"
    "Time-aware LSTM code taken from: https://github.com/duskybomb/tlstm"
    "Time-aware LSTM paper: http://biometrics.cse.msu.edu/Publications/MachineLearning/Baytasetal_PatientSubtypingViaTimeAwareLSTMNetworks.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756b77b-40ea-4e74-a509-528537ff3a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, cuda_flag=False, bidirectional=True):\n",
    "        # assumes that batch_first is always true\n",
    "        super(TimeLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.cuda_flag = cuda_flag\n",
    "        self.W_all = nn.Linear(hidden_size, hidden_size * 4)\n",
    "        self.U_all = nn.Linear(input_size, hidden_size * 4)\n",
    "        self.W_d = nn.Linear(hidden_size, hidden_size)\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "    def forward(self, inputs, timestamps, reverse=False):\n",
    "        # inputs: [b, seq, embed]\n",
    "        # h: [b, hid]\n",
    "        # c: [b, hid]\n",
    "        b, seq, embed = inputs.size()\n",
    "        h = torch.zeros(b, self.hidden_size, requires_grad=False)\n",
    "        c = torch.zeros(b, self.hidden_size, requires_grad=False)\n",
    "        if self.cuda_flag:\n",
    "            h = h.cuda()\n",
    "            c = c.cuda()\n",
    "        outputs = []\n",
    "        for s in range(seq):\n",
    "            c_s1 = torch.tanh(self.W_d(c))\n",
    "            \n",
    "            c_s2 = c_s1 * timestamps[:, s:s + 1].expand_as(c_s1)\n",
    "            c_l = c - c_s1\n",
    "            c_adj = c_l + c_s2\n",
    "            outs = self.W_all(h) + self.U_all(inputs[:, s])\n",
    "            f, i, o, c_tmp = torch.chunk(outs, 4, 1)\n",
    "            f = torch.sigmoid(f)\n",
    "            i = torch.sigmoid(i)\n",
    "            o = torch.sigmoid(o)\n",
    "            c_tmp = torch.sigmoid(c_tmp)\n",
    "            c = f * c_adj + i * c_tmp\n",
    "            h = o * torch.tanh(c)\n",
    "            outputs.append(h)\n",
    "        if reverse:\n",
    "            outputs.reverse()\n",
    "        outputs = torch.stack(outputs, 1)\n",
    "        return outputs\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size= 19, hidden_layer_size=100, output_size=2, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = TimeLSTM(input_size, hidden_layer_size, bidirectional=True)#nn.LSTM(input_size, hidden_lTimeLSTM(input_size, hidden_layer_size, bidirectional=True)ayer_size, batch_first=True, bidirectional=True)###TimeLSTM(input_size, hidden_layer_size, bidirectional=True)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        #self.hidden_cell = (torch.zeros(1,self.batch_size,self.hidden_layer_size),\n",
    "        #                    torch.zeros(1,self.batch_size,self.hidden_layer_size))\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_seq, ts):\n",
    "        #print(input_seq.shape)\n",
    "        lstm_out = self.lstm(input_seq.float(),ts.float())\n",
    "        linear = self.linear(lstm_out[:,-1,:])\n",
    "        #print(lstm_out[:,-1,:])\n",
    "        predictions = self.relu(linear)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2543af82-77ea-4b35-8010-72e2ffc74f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM()\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ff2c27-8494-4d0f-a918-e2544ea191d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_loss(output,target):\n",
    "    loss = (output-target).pow(2).sum(1).sqrt().mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8243ee-7adb-4343-a0fc-c3b37c3aae3e",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b99206-d2d5-4c28-ae46-c84552529ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(train_loader, train_ts, model, optimizer, loss_function, epochs):\n",
    "    for i in range(epochs):\n",
    "        y_preds = []\n",
    "        for j,data in enumerate(train_loader):\n",
    "            x=data[0]\n",
    "            y=data[1]\n",
    "            t=data[2]\n",
    "            optimizer.zero_grad()\n",
    "            #model.hidden_cell = (torch.zeros(1, 64, model.hidden_layer_size),\n",
    "            #                torch.zeros(1, 64, model.hidden_layer_size))\n",
    "            \n",
    "            y_pred = model(torch.tensor(x.float()),data[2].float())\n",
    "            y_preds.append(y_pred)\n",
    "            single_loss = eucl_loss(y_pred, y.float())\n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "    return model, y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cbd442-030d-4ba5-9179-a5ac25a9ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, y_preds = model_training(train_loader, X_train_ts, model, optimizer, loss_function, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f5bf8-c597-46e6-a2b1-9635d6fafa8c",
   "metadata": {},
   "source": [
    "#### Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ad112-7473-4cc3-8ea2-e347c6c3a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_predictions(test_loader, model, scaler):\n",
    "    test_preds = []\n",
    "    model.eval()\n",
    "    \n",
    "    for j,data in enumerate(test_loader):\n",
    "        x=data[0]\n",
    "        y=data[1]\n",
    "        t=data[2]\n",
    "        with torch.no_grad():\n",
    "            test_preds.append(model(x,t))\n",
    "    \n",
    "    list_vals = [t.tolist() for t in test_preds]\n",
    "    actual_predictions = scaler.inverse_transform(np.array([item for sublist in list_vals for item in sublist]))\n",
    "    actual_test_results = scaler.inverse_transform(y)\n",
    "    return actual_predictions, actual_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3824fbc8-dd51-40d0-90b7-bead206c4b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_predictions, actual_test_results = get_test_predictions(test_loader, model, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff739618-71eb-42ae-b206-aa4e0456580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_test_results = scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84a52d2-398f-43c6-8784-03185a1aba62",
   "metadata": {},
   "source": [
    "#### Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a8163b-0402-4da7-94be-a5c2549da98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_analytics(actual_predictions, actual_test_results):\n",
    "    plt.plot(actual_predictions)\n",
    "    plt.plot(actual_test_results)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Dist: \", np.mean([math.dist(actual_predictions[i],actual_test_results[i]) for i in range(len(actual_predictions))]))\n",
    "    print(\"X Dist: \", np.mean(abs(actual_predictions[:,0] - actual_test_results[:,0])))\n",
    "    print(\"Y Dist: \", np.mean(abs(actual_predictions[:,1] - actual_test_results[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34ad0a7-5220-4b29-a122-46bce65be9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_analytics(actual_predictions, actual_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fff936f-94b1-4a9a-8314-36393f8b6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = [t.tolist() for t in y_preds]\n",
    "actual_train_preds = scaler.inverse_transform(np.array([item for sublist in train_preds for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017baf6a-8117-42de-8075-83bf2f60a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_analytics(actual_train_preds,scaler.inverse_transform(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72473043-088e-4ff0-a1ba-1c63e169be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_train_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b4292-23b0-4d36-a18b-da97bfd7b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = whole_cat_input.head(48814)\n",
    "train_cat['pred_x'] = actual_train_preds[:,0]\n",
    "train_cat['pred_y'] = actual_train_preds[:,1]\n",
    "train_cat['actual_x'] = scaler.inverse_transform(y_train)[:,0]\n",
    "train_cat['actual_y'] = scaler.inverse_transform(y_train)[:,1]\n",
    "tc_event = train_cat.loc[12].head(22)\n",
    "tc_event = tc_event.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1082776f-0161-4360-bbc1-ce3088db5932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mplsoccer import Pitch\n",
    "pitch = Pitch(pitch_type='uefa', pitch_length = 105, pitch_width=68,pitch_color='green')\n",
    "fig,ax = pitch.draw()\n",
    "#fig,ax = plot_functions.plot_pitch()\n",
    "fig.set_size_inches(16,9)\n",
    "nums = [1,2,3,4,5,6,7,8,9,10,11]\n",
    "nums2 = [12,13,14,15,16,17,18,19,20,21,22]\n",
    "ax.scatter(tc_event['pred_x'].head(11).drop(index=6),tc_event['pred_y'].head(11).drop(index=6),s=300, label='Predicted Positions',color='navy')\n",
    "ax.scatter(tc_event['actual_x'].head(11).drop(index=6),tc_event['actual_y'].head(11).drop(index=6),s=300, label='Actual Positions',color='white')\n",
    "ax.scatter(tc_event['actual_x'].loc[6],tc_event['actual_y'].loc[6],s=300,c='black', label='Ball Carrier Position')\n",
    "for i,txt in enumerate(nums):\n",
    "    if txt == 7:\n",
    "        ax.annotate(txt, [(tc_event['actual_x']).iloc[i],(tc_event['actual_y']).iloc[i]+1],size=20)\n",
    "    else:\n",
    "        ax.annotate(txt, [(tc_event['pred_x']).iloc[i],(tc_event['pred_y']).iloc[i]+1],size=20)\n",
    "        ax.annotate(txt, [(tc_event['actual_x']).iloc[i],(tc_event['actual_y']).iloc[i]+1],size=20)\n",
    "        \n",
    "ax.legend(loc=9,prop={'size':20})\n",
    "fig.savefig('pitch_preds.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b223165-16b1-4c29-be6a-8f746dcbc11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vals = whole_num_input.head(319898).reset_index(drop=True)\n",
    "known_preds = (train_vals[train_vals['prev_player_x'] == train_vals['next_player_x']]).index\n",
    "base_2_pred_x = []\n",
    "base_2_pred_y = []\n",
    "base_2_pred_x = base_2_pred_x + list(train_vals['prev_player_x'][:known_preds[0]+1].values)\n",
    "base_2_pred_y = base_2_pred_y + list(train_vals['prev_player_y'][:known_preds[0]+1].values)\n",
    "for i in range(1,len(known_preds)):\n",
    "    events_since_last_seen = train_vals[known_preds[i-1]:known_preds[i]+1]\n",
    "    cum_time = events_since_last_seen['time_since_last_pred'].head(-1).cumsum()\n",
    "    sum_time = events_since_last_seen['time_since_last_pred'].sum()\n",
    "    #print(((cum_time/sum_time) *(abs(base_x_test.loc[known_preds[i-1]]['prev_player_x'] - base_x_test.loc[known_preds[i]]['prev_player_x']))).values)\n",
    "    new_preds_x = list(((cum_time/sum_time) * (abs(train_vals.loc[known_preds[i-1]]['prev_player_x'] - train_vals.loc[known_preds[i]]['prev_player_x']))).values)\n",
    "    if train_vals.loc[known_preds[i-1]]['prev_player_x'] < train_vals.loc[known_preds[i]]['prev_player_x']:\n",
    "        ps_x = new_preds_x + train_vals.loc[known_preds[i-1]]['prev_player_x']\n",
    "    else:\n",
    "        ps_x = abs(new_preds_x - train_vals.loc[known_preds[i-1]]['prev_player_x'])\n",
    "\n",
    "    new_preds_y = list(((cum_time/sum_time) * (abs(train_vals.loc[known_preds[i-1]]['prev_player_y'] - train_vals.loc[known_preds[i]]['prev_player_y']))).values)\n",
    "    if train_vals.loc[known_preds[i-1]]['prev_player_y'] < train_vals.loc[known_preds[i]]['prev_player_y']:\n",
    "        ps_y = new_preds_y + train_vals.loc[known_preds[i-1]]['prev_player_y']\n",
    "    else:\n",
    "        ps_y = abs(new_preds_y - train_vals.loc[known_preds[i-1]]['prev_player_y'])\n",
    "\n",
    "    if np.isnan(ps_x).sum() > 0:\n",
    "        ps_x = train_vals[known_preds[i-1]:known_preds[i]]['prev_player_x']\n",
    "        ps_y = train_vals[known_preds[i-1]:known_preds[i]]['prev_player_y']\n",
    "\n",
    "    base_2_pred_x = base_2_pred_x + list(ps_x)\n",
    "    base_2_pred_y = base_2_pred_y + list(ps_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd86f5-754e-41ec-a172-99886288ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "train_cat['bl_x'] = base_2_pred_x\n",
    "train_cat['bl_y'] = base_2_pred_y\n",
    "cf_heatmap = train_cat[train_cat['position'] == 'LW'].tail(2107)\n",
    "pitch = Pitch(pitch_type='uefa', pitch_length = 105, pitch_width=68,pitch_color='green')\n",
    "fig,ax = pitch.draw()\n",
    "#fig,ax = plot_functions.plot_pitch()\n",
    "fig.set_size_inches(16,9)\n",
    "sns.kdeplot(cf_heatmap['actual_x'],cf_heatmap['actual_y'],shade=\"True\",label='Actual',legend=True,alpha=1)\n",
    "plt.title('Actual Heatmap for RW',fontsize=35)\n",
    "fig.savefig('actual_rw.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a2824-cbb3-4f17-a024-0f03bcffc326",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_heatmap[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d011c20-ca1a-4636-b5da-4cc33f330d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_heatmap = train_cat[train_cat['position'] == 'LW'].tail(2107)\n",
    "pitch = Pitch(pitch_type='uefa', pitch_length = 105, pitch_width=68,pitch_color='green')\n",
    "fig,ax = pitch.draw()\n",
    "#fig,ax = plot_functions.plot_pitch()\n",
    "fig.set_size_inches(16,9)\n",
    "sns.kdeplot(cf_heatmap['bl_x'],cf_heatmap['bl_y'],shade=\"True\",label='Actual',legend=True,alpha=1)\n",
    "plt.title('Baseline Heatmap for RW',fontsize=35)\n",
    "fig.savefig('bl_rw.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167157f1-2457-4543-8411-1501f6f7bd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cf_heatmap = train_cat[train_cat['position'] == 'LW'].tail(2107)\n",
    "pitch = Pitch(pitch_type='uefa', pitch_length = 105, pitch_width=68,pitch_color='green')\n",
    "fig,ax = pitch.draw()\n",
    "#fig,ax = plot_functions.plot_pitch()\n",
    "fig.set_size_inches(16,9)\n",
    "sns.kdeplot(cf_heatmap['pred_x'],cf_heatmap['pred_y'],shade=\"True\",label='Actual',legend=True,alpha=1)\n",
    "plt.title('Predicted Heatmap for RW',fontsize=35)\n",
    "fig.savefig('pred_rw.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c3cd9b-aaa3-48c3-841f-e4f7dad4cdfa",
   "metadata": {},
   "source": [
    "- Make sequences work better\n",
    "- Diagnose why sequences are working so badly\n",
    "- Now considers a team not swapping both sides & outputs x&y, gets all home players for 1 game\n",
    "- Look into adding multiple LSTMs for each player - see if anything online/github with similar architecture - GNN\n",
    "- Need a marker to say whether the player is still on the pitch or not\n",
    "- Add position changes to database\n",
    "- Streamline training to be faster - avoid loops/add cuda\n",
    "- Change batch size?\n",
    "- Check over loss function\n",
    "- Add data for all teams\n",
    "- Windowed average location\n",
    "- Add baseline + XGBoost model to this to use as comparators\n",
    "\n",
    "TODO\n",
    "- Look into GNN using location predictions\n",
    "- LSTM for each player position?\n",
    "- Formation changes\n",
    "- Scoreline as feature\n",
    "- Windowed average\n",
    "- Check that formation change makes sense for players e.g. CB moving to CF does that make sense in Tracking_Tests?\n",
    "- Find known player positions and make the imputation the exact point\n",
    "- Imputation with varying difference in timestep\n",
    "\n",
    "Get the prediction at each event in a game by attaching match id and event num to each prediction. Can then predict simultaneously and use GNN to link together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150179ac-6b11-4bb7-8fa2-83b9c595c5d6",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a674f00e-25bb-4d08-929d-1bc4c9a557a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_categories = pd.DataFrame([])\n",
    "xg_categories['position'] = pd.Categorical(whole_cat_input['position']).codes\n",
    "xg_categories['event_type'] = pd.Categorical(whole_cat_input['event_type']).codes\n",
    "xg_categories['team_on_ball'] = pd.Categorical(whole_cat_input['team_on_ball']).codes\n",
    "xg_categories['player_on_ball'] = pd.Categorical(whole_cat_input['player_on_ball']).codes\n",
    "xg_categories['goal_diff'] = pd.Categorical(whole_cat_input['goal_diff']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611fa3a-e69d-48fa-b144-8842d446dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_x_train = whole_num_input[:math.floor(len(whole_num_input)*0.9)].reset_index(drop=True)\n",
    "base_x_train_cat = whole_cat_input[:math.floor(len(whole_num_input)*0.9)].reset_index(drop=True)\n",
    "base_x_test = whole_num_input[math.floor(len(whole_num_input)*0.9):].reset_index(drop=True)\n",
    "base_x_test_cat = whole_cat_input[math.floor(len(whole_num_input)*0.9):].reset_index(drop=True)\n",
    "base_y_train = whole_label[:math.floor(len(whole_num_input)*0.9)]\n",
    "base_y_test = whole_label[math.floor(len(whole_num_input)*0.9):]\n",
    "xg_cat_train = xg_categories[:math.floor(len(whole_num_input)*0.9)].reset_index(drop=True)\n",
    "xg_cat_test = xg_categories[math.floor(len(whole_num_input)*0.9):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f334fab-d97a-4ac5-8985-885f1224ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_1(x_test, y_test):\n",
    "    pred_x = np.array((x_test['prev_player_x']+x_test['next_player_x']) / 2)\n",
    "    pred_y = np.array((x_test['prev_player_y']+x_test['next_player_y']) / 2)\n",
    "    base_dist_error = np.mean([math.dist([[a,b] for a,b in zip(pred_x,pred_y)][i],y_test[i]) for i in range(len(pred_x))])\n",
    "    return base_dist_error\n",
    "\n",
    "print(\"Baseline 1 distance error: \", baseline_1(base_x_test, base_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c51159f-e739-4a7c-b798-4186f5eecc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_2(x_test, y_test):\n",
    "    known_preds = (x_test[x_test['prev_player_x'] == x_test['next_player_x']]).index\n",
    "    base_2_pred_x = []\n",
    "    base_2_pred_y = []\n",
    "    base_2_pred_x = base_2_pred_x + list(x_test['prev_player_x'][:known_preds[0]+1].values)\n",
    "    base_2_pred_y = base_2_pred_y + list(x_test['prev_player_y'][:known_preds[0]+1].values)\n",
    "    for i in range(1,len(known_preds)):\n",
    "        events_since_last_seen = x_test[known_preds[i-1]:known_preds[i]+1]\n",
    "        cum_time = events_since_last_seen['time_since_last_pred'].head(-1).cumsum()\n",
    "        sum_time = events_since_last_seen['time_since_last_pred'].sum()\n",
    "        #print(((cum_time/sum_time) *(abs(base_x_test.loc[known_preds[i-1]]['prev_player_x'] - base_x_test.loc[known_preds[i]]['prev_player_x']))).values)\n",
    "        new_preds_x = list(((cum_time/sum_time) * (abs(x_test.loc[known_preds[i-1]]['prev_player_x'] - x_test.loc[known_preds[i]]['prev_player_x']))).values)\n",
    "        if x_test.loc[known_preds[i-1]]['prev_player_x'] < x_test.loc[known_preds[i]]['prev_player_x']:\n",
    "            ps_x = new_preds_x + x_test.loc[known_preds[i-1]]['prev_player_x']\n",
    "        else:\n",
    "            ps_x = abs(new_preds_x - x_test.loc[known_preds[i-1]]['prev_player_x'])\n",
    "\n",
    "        new_preds_y = list(((cum_time/sum_time) * (abs(x_test.loc[known_preds[i-1]]['prev_player_y'] - x_test.loc[known_preds[i]]['prev_player_y']))).values)\n",
    "        if x_test.loc[known_preds[i-1]]['prev_player_y'] < x_test.loc[known_preds[i]]['prev_player_y']:\n",
    "            ps_y = new_preds_y + x_test.loc[known_preds[i-1]]['prev_player_y']\n",
    "        else:\n",
    "            ps_y = abs(new_preds_y - x_test.loc[known_preds[i-1]]['prev_player_y'])\n",
    "\n",
    "        if np.isnan(ps_x).sum() > 0:\n",
    "            ps_x = x_test[known_preds[i-1]:known_preds[i]]['prev_player_x']\n",
    "            ps_y = x_test[known_preds[i-1]:known_preds[i]]['prev_player_y']\n",
    "\n",
    "        base_2_pred_x = base_2_pred_x + list(ps_x)\n",
    "        base_2_pred_y = base_2_pred_y + list(ps_y)\n",
    "    base_dist_error = np.mean([math.dist([[a,b] for a,b in zip(base_2_pred_x,base_2_pred_y)][i],y_test[i]) for i in range(len(base_2_pred_x))])\n",
    "    return base_dist_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614a357-2213-4a53-9103-dd2f33481ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Baseline 2 distance error: \", baseline_2(base_x_test, base_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aebe28-c8ce-49a2-9061-065631f52249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "def all_xgboost_regression_model(x_train,y_train,x_test,y_test):\n",
    "    model = MultiOutputRegressor(XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.8, subsample=0.3, learning_rate = 0.015, max_depth = 7, gamma = 5, n_estimators = 400))\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = pd.DataFrame(model.predict(x_test), columns=['X','Y'])\n",
    "    train_preds = pd.DataFrame(model.predict(x_train), columns=['X','Y'])\n",
    "    return predictions, train_preds, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9724b4-d1cd-4cca-8cf2-1e0e47aac7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xg_boost_baseline(base_x_train, xg_cat_train, base_x_test, xg_cat_test, base_y_train, base_y_test):\n",
    "    xg_x_train = pd.concat([base_x_train,xg_cat_train],axis=1)\n",
    "    xg_x_test = pd.concat([base_x_test,xg_cat_test],axis=1)\n",
    "    xg_test_preds,xg_train_preds,model = all_xgboost_regression_model(xg_x_train,base_y_train,xg_x_test,base_y_test)\n",
    "    return np.mean([math.dist(xg_test_preds.loc[i],base_y_test[i]) for i in range(len(xg_test_preds))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65283619-e433-4063-bf1c-9a4303e5470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"XGBoost Regressor Distance Error: \", xg_boost_baseline(base_x_train, xg_cat_train, base_x_test, xg_cat_test, base_y_train, base_y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
